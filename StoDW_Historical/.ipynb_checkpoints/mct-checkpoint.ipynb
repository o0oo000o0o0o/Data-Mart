{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PostgreSQL Connection\n",
    "try:\n",
    "    pg_db = psycopg2.connect(host=\"165.22.220.96\",user=\"praveen\",password=\"Admin123\",database=\"staging\")\n",
    "    pg_db.autocommit = True\n",
    "    pgcursor = pg_db.cursor()\n",
    "    print(\"PostgreSQL Connection Established\")\n",
    "except psycopg2.OperationalError as e:\n",
    "    print(\"Unable to Connect: \",format(e))\n",
    "    \n",
    "    \n",
    "#PostgreSQL Connection\n",
    "# try:\n",
    "#     pg_db1 = psycopg2.connect(host=\"165.22.220.96\",user=\"praveen\",password=\"Admin123\",database=\"staging\")\n",
    "#     pg_db1.autocommit = True\n",
    "#     pgcursor1 = pg_db1.cursor()\n",
    "#     print(\"PostgreSQL Connection Established\")\n",
    "# except psycopg2.OperationalError as e:\n",
    "#     print(\"Unable to Connect: \",format(e))\n",
    "\n",
    "# #PostgreSQL Connection 2\n",
    "# try:\n",
    "#     pg_db2 = psycopg2.connect(host=\"165.22.220.96\",user=\"praveen\",password=\"Admin123\",database=\"staging\")\n",
    "#     pg_db2.autocommit = True\n",
    "#     pgcursor2 = pg_db2.cursor()\n",
    "#     print(\"PostgreSQL Connection Established\")\n",
    "# except psycopg2.OperationalError as e:\n",
    "#     print(\"Unable to Connect: \",format(e))\n",
    "    \n",
    "# #PostgreSQL Connection 3\n",
    "# try:\n",
    "#     pg_db3 = psycopg2.connect(host=\"165.22.220.96\",user=\"praveen\",password=\"Admin123\",database=\"staging\")\n",
    "#     pg_db3.autocommit = True\n",
    "#     pgcursor3 = pg_db3.cursor()\n",
    "#     print(\"PostgreSQL Connection Established\")\n",
    "# except psycopg2.OperationalError as e:\n",
    "#     print(\"Unable to Connect: \",format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pgcursor.execute(\"select * from master_customer_test\")\n",
    "# master=pd.DataFrame(pgcursor.fetchall(),columns = [x[0] for x in pgcursor.description]).head(31)\n",
    "# master=master.loc[:,:'email_address']\n",
    "# master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pgcursor.execute(\"Select * from mct\")\n",
    "df=pd.DataFrame(pgcursor.fetchall(),columns = [x[0] for x in pgcursor.description])\n",
    "df = df.replace(r'^([\\s])$|^(?![\\s\\S])$', np.nan, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['email_address'].unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "\n",
    "## EMAIL_STATUS :: NO NEED OF THE COLUMN\n",
    "## Publisher_Name,customer_id :: No Need\n",
    "## ORDER_TYPE :: UPDATE ALL NULL VALUES WITH 1 \n",
    "# \"1\" = distribution order\n",
    "# \"2\" = conversion order\n",
    "# 0= no order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_name():\n",
    "    column_specific = email_specific[['date_created','first_name']]\\\n",
    "                        [(email_specific['address_line1'].isna()==False)]    \n",
    "    return column_specific\n",
    " \n",
    "def last_name():\n",
    "    column_specific = email_specific[['date_created','last_name']]\\\n",
    "                        [(email_specific['last_name'].isna()==False)]\n",
    "    return column_specific\n",
    "\n",
    "def address_line1():\n",
    "    column_specific = email_specific[['date_created','address_line1','address_line2','city','state','country','zip']]\\\n",
    "                    [(email_specific['address_line1'].isna()==False)]\n",
    "    return column_specific\n",
    " \n",
    "def phone():\n",
    "    column_specific = email_specific[['date_created','phone']]\\\n",
    "                    [(email_specific['phone'].isna()==False)]\n",
    "    return column_specific\n",
    "\n",
    "def fax():\n",
    "    column_specific = email_specific[['date_created','fax']]\\\n",
    "                    [(email_specific['fax'].isna()==False)]\n",
    "    return column_specific\n",
    "\n",
    "def website():\n",
    "    column_specific = email_specific[['date_created','website']]\\\n",
    "                    [(email_specific['website'].isna()==False)]\n",
    "    return column_specific\n",
    "\n",
    "def is_partner():\n",
    "    column_specific = email_specific[['date_created','is_partner']]\\\n",
    "                    [(email_specific['is_partner'].isna()==False)]\n",
    "    return column_specific\n",
    "\n",
    "def date_of_sale():\n",
    "    column_specific = email_specific[['date_created','date_of_sale']]\\\n",
    "                    [(email_specific['date_of_sale'].isna()==False)]\n",
    "    return column_specific\n",
    "\n",
    "def lead_owner():\n",
    "    column_specific = email_specific[['date_created','lead_owner']]\\\n",
    "                    [(email_specific['lead_owner'].isna()==False)]\n",
    "    return column_specific\n",
    "\n",
    "def lead_source():\n",
    "    column_specific = email_specific[['date_created','lead_source']]\\\n",
    "                    [(email_specific['lead_source'].isna()==False)]\n",
    "    return column_specific\n",
    "\n",
    "def order_type():\n",
    "    column_specific = email_specific[['date_created','order_type']]\\\n",
    "                    [(email_specific['order_type'].isna()==False)]\n",
    "    return column_specific\n",
    "\n",
    "switcher = {\n",
    "        0: first_name,\n",
    "        1: last_name,\n",
    "        2: address_line1,\n",
    "        3: phone,\n",
    "        4: fax,\n",
    "        5: website,\n",
    "        6: is_partner,\n",
    "        7: date_of_sale,\n",
    "        8: lead_owner,\n",
    "        9: lead_source,\n",
    "        10: order_type\n",
    "    }\n",
    " \n",
    "\n",
    "def sub_df(argument):\n",
    "    # Get the function from switcher dictionary\n",
    "    func = switcher.get(argument, \"nothing\")\n",
    "    # Execute the function\n",
    "    return func()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in df['email_address'].unique()[0:5]:\n",
    "    print(i)\n",
    "    # extracting those rows that have email_addresses = i\n",
    "    email_specific = df[df['email_address']==i] \n",
    "    display\n",
    "    \n",
    "    for num in range(0,11):\n",
    "        print(num)\n",
    "        display(sub_df(num))\n",
    "    print('---------')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in df['email_address'].unique():\n",
    "    print(i)\n",
    "    \n",
    "    # Creating a new dataframe using rows that have email_address = i\n",
    "    c = df[df['email_address']==i]\n",
    "    \n",
    "    # Extract first names to filter out based on frequency for golden record\n",
    "    fn = c['first_name'].tolist()\n",
    "    \n",
    "    #Removing blank/space values from existing names\n",
    "    fn = list(filter(lambda k: 'nan' not in k, fn))\n",
    "    \n",
    "    # Get frequency counts of each of the names\n",
    "    first_name = {x:fn.count(x) for x in fn}\n",
    "    print(\"first_name:\",first_name)\n",
    "    \n",
    "    # Checking for ties in frequencies by finding unique counts values\n",
    "    first_name_set = set(val for val in first_name.values())\n",
    "    print(\"First Name Counts:\",first_name_set)\n",
    "    \n",
    "    # if lengths of dictionary and set are equal = no ties between names = get value with highest frequency\n",
    "    # if lengths are not equal = frequencies tied between two names = get the oldest name\n",
    "    if len(first_name_set) == len(first_name):\n",
    "        freq_value = max(first_name, key=first_name.get)\n",
    "        print(\"Most freq name:\",freq_value)\n",
    "        \n",
    "        print(\"---------\")\n",
    "    else:\n",
    "        date_created = min(c['date_created'].tolist())\n",
    "        print(date_created)\n",
    "        \n",
    "        idx = c[c['date_created']==date_created].index\n",
    "        f = list(c.loc[idx,'first_name'])\n",
    "        print(\"Oldest First Name:\",f[0])\n",
    "        \n",
    "        print(\"---------\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in df['email_address'].unique():\n",
    "    \n",
    "    # extracting those rows that have email_addresses = i\n",
    "    c = df[(df['email_address']==i) & (df['last_name'].isna()==False)]\n",
    "#     print(c)\n",
    "\n",
    "    # extract values to filter out based on frequency for golden record\n",
    "    ln = c['last_name'].tolist()\n",
    "    print(ln)\n",
    "    \n",
    "    #Get frequency counts of each last name in list\n",
    "    last_names = {x:ln.count(x) for x in ln}\n",
    "    print(\"last name:\",last_names)\n",
    "    \n",
    "    # Checking for ties in frequencies by finding unique counts values\n",
    "    last_name_set = set(val for val in last_names.values())\n",
    "    print(\"last_name_set:\",last_name_set)\n",
    "    \n",
    "    # if lengths of dictionary and set are equal = no ties between names = get value with highest frequency\n",
    "    # if lengths are not equal = frequencies tied between two names = get the oldest name\n",
    "    if len(last_name_set) == len(last_names):\n",
    "        freq_value = max(last_names, key=last_names.get)\n",
    "        print(\"Most freq name:\",freq_value)\n",
    "        \n",
    "        print(\"---------\")\n",
    "    else:\n",
    "        date_created = min(c['date_created'].tolist())\n",
    "        print(date_created)\n",
    "        \n",
    "        idx = c[c['date_created']==date_created].index\n",
    "#         print(idx)\n",
    "        l = list(c.loc[idx,'last_name'])\n",
    "        print(l[0])\n",
    "        \n",
    "        print(\"---------\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Address Columns [address_line1,address_line2,city,state,country,zip]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df['email_address'].unique():\n",
    "    \n",
    "    # extracting address columns and rows that satisfy two conditions: \n",
    "    # email_addresses = i and address_line1 is not NaN\n",
    "    column_specific = df[['date_created','address_line1','address_line2','city','state','country','zip']][(df['email_address']==i) & (df['address_line1'].isna()==False)]\n",
    "#     print(column_specific,'\\n')\n",
    "    \n",
    "    if column_specific.shape[0] == 1:\n",
    "        print('*************')\n",
    "        print(\"Only One Row:\")\n",
    "#         print(column_specific)\n",
    "        \n",
    "        adl1 = column_specific.iloc[0].address_line1\n",
    "        adl2 = column_specific.iloc[0].address_line2\n",
    "        city = column_specific.iloc[0].city\n",
    "        state = column_specific.iloc[0].state\n",
    "        country = column_specific.iloc[0].country\n",
    "        zip = column_specific.iloc[0].zip\n",
    "#         print(adl1,adl2,city,state,country,zip)\n",
    "#         print('*************')\n",
    "        \n",
    "    else:\n",
    "        # extract addresses to filter out based on frequency for golden record\n",
    "        address_lst = column_specific['address_line1'].tolist()\n",
    "#         print(\"address_lst:\",address_lst,'\\n')\n",
    "\n",
    "        #Frequency counts of each address in list\n",
    "        address_counts = {x:address_lst.count(x) for x in address_lst}\n",
    "        \n",
    "#         print(\"address_counts:\",address_counts,\":: set counts:\",set(address_counts.values()),'\\n')\n",
    "\n",
    "        # A set cannot have duplicate values, it takes the unique of dictionary values. \n",
    "        # Length of set = 1 only when all values in dictionary are the same [Ties might exist]\n",
    "        if (len(address_counts) > len(set(address_counts.values()))) \\\n",
    "                & (sum(x==max(address_counts.values()) for x in address_counts.values()) == 1):\n",
    "            \n",
    "            # Getting most frequent value of column\n",
    "            freq_value = max(address_counts, key=address_counts.get)\n",
    "#             print('freq_value:',freq_value,'\\n')\n",
    "            \n",
    "            # Extracting rows that contain the most frequent value\n",
    "            freq_df = column_specific[column_specific['address_line1'] == freq_value]\n",
    "#             print('FINAL FREQ RECORD')\n",
    "#             print(freq_df,'\\n')\n",
    "\n",
    "#             print('-----------')\n",
    "#             print('-----------')\n",
    "        else:\n",
    "            \n",
    "            # Selecting rows with minimum missing values\n",
    "            # Count number of columns that have max non-null values \n",
    "            count = max(column_specific.count(axis=1))\n",
    "#             print(\"count:\",count)\n",
    "            \n",
    "            # Get rows with maximum number of non-null values\n",
    "            min_df = column_specific.dropna(thresh=count)\n",
    "            print('min_df')\n",
    "            print(min_df,'\\n')\n",
    "            \n",
    "            # Extract the most recent record of the above dataframe\n",
    "            date_created = max(min_df['date_created'].tolist())\n",
    "    #         print(date_created)\n",
    "    \n",
    "            recent_record = min_df[(min_df['date_created']==date_created)].iloc[:,1:]#.values.tolist()[0]\n",
    "#             print('FINAL RECENT RECORD')\n",
    "#             print(recent_record)\n",
    "            \n",
    "#             print('-----------')\n",
    "#             print('-----------')\n",
    "\n",
    "    print(\"---------------------------------------------------------------\")\n",
    "        \n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in df['email_address'].unique():\n",
    "    \n",
    "    # extracting address columns and rows that satisfy two conditions: \n",
    "    # email_addresses = i and address_line1 is not NaN\n",
    "    column_specific = df[['date_created','phone']][(df['email_address']==i) & (df['phone'].isna()==False)]\n",
    "    column_specific['phone'] = column_specific['phone'].str.replace('\\W', '')\n",
    "    print(column_specific,'\\n')\n",
    "    \n",
    "    if column_specific.shape[0] == 0:\n",
    "        print(np.nan)\n",
    "        \n",
    "    elif column_specific.shape[0] == 1:\n",
    "        print('*************')\n",
    "        print(\"Only One Row:\")\n",
    "        print(column_specific)\n",
    "        print('*************')\n",
    "        \n",
    "    else:\n",
    "        # extract addresses to filter out based on frequency for golden record\n",
    "        phn_lst = column_specific['phone'].tolist()\n",
    "#         print(\"phn_lst:\",phn_lst,'\\n')\n",
    "\n",
    "        #Frequency counts of each address in list\n",
    "        phone_counts = {x:phn_lst.count(x) for x in phn_lst}\n",
    "        print(\"phone_counts:\",phone_counts,\":: set counts:\",set(phone_counts.values()),'\\n')\n",
    "        \n",
    "        if len(phone_counts) == 1:\n",
    "            print(list(phone_counts.keys())[0])\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            # Extract the most recent record of the above dataframe\n",
    "            date_created = max(column_specific['date_created'].tolist())\n",
    "            print(date_created,'\\n')\n",
    "\n",
    "            recent_record = column_specific['phone'][(column_specific['date_created']==date_created)].values.tolist()[0]\n",
    "            print('FINAL RECENT RECORD')\n",
    "            print(recent_record)\n",
    "\n",
    "    print(\"--------\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_db.close()\n",
    "# pg_db1.close()\n",
    "# pg_db2.close()\n",
    "# pg_db3.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
