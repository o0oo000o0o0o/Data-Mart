{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine, inspect\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postgres_engine = create_engine('postgresql://praveen:Admin123@165.22.220.96:5432/staging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PostgreSQL Connection\n",
    "try:\n",
    "    pg_db = psycopg2.connect(host=\"165.22.220.96\",user=\"praveen\",password=\"Admin123\",database=\"staging\")\n",
    "    pg_db.autocommit = True\n",
    "    pgcursor = pg_db.cursor()\n",
    "    print(\"PostgreSQL Connection Established\")\n",
    "except psycopg2.OperationalError as e:\n",
    "    print(\"Unable to Connect: \",format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stg_crm = pd.read_sql('SELECT * FROM stg_crm_customer', con=postgres_engine)\n",
    "stg_bpm = pd.read_sql('SELECT * FROM stg_bpm_client_info', con=postgres_engine)\n",
    "stg_blc = pd.read_sql('SELECT * FROM stg_blc_customer', con=postgres_engine)\n",
    "master = pd.read_sql('SELECT * FROM master_customer_test', con=postgres_engine)\n",
    "master = master.drop(['master_customer_id','created_date','updated_date'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EMAIL_STATUS :: NO NEED OF THE COLUMN\n",
    "## Publisher_Name,customer_id :: No Need\n",
    "## ORDER_TYPE :: UPDATE ALL NULL VALUES WITH 1 \n",
    "# \"1\" = distribution order\n",
    "# \"2\" = conversion order\n",
    "# 0= no order\n",
    "\n",
    "master.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stg_crm[\"role_id\"] = 1\n",
    "stg_crm = stg_crm.rename(columns={\"locality\": \"city\", \"region\": \"state\", \"country_code\": \"country\", \n",
    "                          \"given_name\": \"first_name\", \"phonenumber\": \"phone\", \"address1\": \"address_line1\", \n",
    "                          \"address2\": \"address_line2\", \"zip_code\": \"zip\"})\n",
    "stg_crm = stg_crm[['customer_id', 'email_address', 'date_created', 'first_name','country', 'phone', 'email_status', \n",
    "           'created_date', 'updated_date','role_id']]\n",
    "stg_crm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Validating Email_addresses Using REGEX\n",
    "crm = stg_crm[stg_crm.email_address.str.contains('[\\w\\.-]+@[\\w\\.-]+', regex= True, na=False)]\n",
    "crm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# stg_crm[~stg_crm.isin(crm)].dropna()\n",
    "# .shape = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_master = master.append(crm)\n",
    "# new_master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stg_bpm.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stg_bpm[\"role_id\"] = 1\n",
    "# stg_bpm = stg_bpm.rename(columns={\"company_name\": \"publisher_name\", \"email\": \"email_address\", \"address\": \"address_line1\", \"date\": \"date_created\", \"clientid\": \"customer_id\"})\n",
    "# stg_bpm = stg_bpm[['customer_id', 'publisher_name', 'address_line1', 'city', 'state','country', 'zip', 'phone', 'fax', \n",
    "#            'email_address','date_created', 'created_date', 'updated_date','role_id']]\n",
    "# stg_bpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #Validating Email_addresses Using REGEX\n",
    "# bpm = stg_bpm[stg_bpm.email_address.str.contains('[\\w\\.-]+@[\\w\\.-]+', regex= True, na=False)]\n",
    "# bpm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = pd.merge(stg_bpm,bpm,on='customer_id',how='outer',indicator=True)\n",
    "# result=result[result['_merge']=='left_only']\n",
    "# print(result.shape)\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in result['publisher_name_x'].unique():\n",
    "#     column_specific = stg_bpm[(stg_bpm['publisher_name']==i)]\n",
    "# #     if column_specific.shape[0] > 1:\n",
    "# #         display(column_specific)\n",
    "        \n",
    "# #         # Howard Shapiro\n",
    "# #         # Colleen Sen\n",
    "        \n",
    "# #     else:\n",
    "#     display(column_specific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_master = new_master.append(bpm)\n",
    "# new_master.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stg_blc = stg_blc[['customer_id', 'date_created','deactivated', 'email_address','first_name', 'last_name', 'password', \n",
    "#            'user_name', 'address_line1', 'city', 'phone', 'zip','country_name', 'state_name', 'role_id',\n",
    "#            'is_publisher', 'publisher_name', 'website', 'is_partner', 'date_of_sale','lead_owner', \n",
    "#            'lead_source', 'order_type', 'created_date','updated_date']]\n",
    "# stg_blc = stg_blc.rename(columns={\"country_name\": \"country\", \"state_name\": \"state\"})\n",
    "# stg_blc = stg_blc.loc[(stg_blc[\"role_id\"] == 1) & pd.notnull(stg_blc[\"address_line1\"])]\n",
    "# stg_blc['order_type'] = stg_blc['order_type'].fillna('1')\n",
    "\n",
    "# stg_blc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Validating Email_addresses Using REGEX\n",
    "# blc = stg_blc[stg_blc.email_address.str.contains('[\\w\\.-]+@[\\w\\.-]+', regex= True, na=False)]\n",
    "# blc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_master = new_master.append(blc)\n",
    "# new_master.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MASTER CUSTOMER TABLE AND GOLDEN RECORD CREATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_master = new_master.drop(['email_status','customer_id','created_date','updated_date'], 1)\n",
    "new_master.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_master['email_address'] = new_master['email_address'].str.lower()\n",
    "new_master = new_master.replace({\"\\'\":\"''\" }, regex=True)\n",
    "new_master = new_master.replace(r'^([\\s])$|^(?![\\s\\S])$', np.nan, regex=True)\n",
    "new_master.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_master['email_address'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_name():\n",
    "    column_specific = email_specific[['date_created','first_name']]\\\n",
    "                        [(email_specific['first_name'].isna()==False)]    \n",
    "    return column_specific\n",
    " \n",
    "def last_name():\n",
    "    column_specific = email_specific[['date_created','last_name']]\\\n",
    "                        [(email_specific['last_name'].isna()==False)]\n",
    "    return column_specific\n",
    "\n",
    "def address_line1():\n",
    "    column_specific = email_specific[['date_created','address_line1','address_line2','city','state','country','zip']]\\\n",
    "                    [(email_specific['address_line1'].isna()==False)]\n",
    "    return column_specific\n",
    " \n",
    "def phone():\n",
    "    column_specific = email_specific[['date_created','phone']]\\\n",
    "                    [(email_specific['phone'].isna()==False)]\n",
    "    return column_specific\n",
    "\n",
    "def fax():\n",
    "    column_specific = email_specific[['date_created','fax']]\\\n",
    "                    [(email_specific['fax'].isna()==False)]\n",
    "    return column_specific\n",
    "\n",
    "def website():\n",
    "    column_specific = email_specific[['date_created','website']]\\\n",
    "                    [(email_specific['website'].isna()==False)]\n",
    "    return column_specific\n",
    "\n",
    "def is_partner():\n",
    "    column_specific = email_specific[['date_created','is_partner']]\\\n",
    "                    [(email_specific['is_partner'].isna()==False)]\n",
    "    return column_specific\n",
    "\n",
    "def lead_owner():\n",
    "    column_specific = email_specific[['date_created','lead_owner']]\\\n",
    "                    [(email_specific['lead_owner'].isna()==False)]\n",
    "    return column_specific\n",
    "\n",
    "def lead_source():\n",
    "    column_specific = email_specific[['date_created','lead_source']]\\\n",
    "                    [(email_specific['lead_source'].isna()==False)]\n",
    "    return column_specific\n",
    "\n",
    "def order_type():\n",
    "    column_specific = email_specific[['date_created','order_type']]\\\n",
    "                    [(email_specific['order_type'].isna()==False)]\n",
    "    return column_specific\n",
    "\n",
    "switcher = {\n",
    "        0: first_name,\n",
    "        1: last_name,\n",
    "        2: address_line1,\n",
    "        3: phone,\n",
    "        4: fax,\n",
    "        5: website,\n",
    "        6: is_partner,\n",
    "        7: lead_owner,\n",
    "        8: lead_source,\n",
    "        9: order_type\n",
    "    }\n",
    " \n",
    "\n",
    "def sub_df(argument):\n",
    "    # Get the function from switcher dictionary\n",
    "    func = switcher.get(argument, \"nothing\")\n",
    "    # Execute the function\n",
    "    return func()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "failed_emails = {}\n",
    "count_failed_emails = 0\n",
    "\n",
    "for i in new_master['email_address'].unique():\n",
    "    display(new_master)\n",
    "    print(i)\n",
    "    try:\n",
    "        data = {}\n",
    "\n",
    "        # Creating a new dataframe using rows that have email_address = i\n",
    "        email_specific = new_master[new_master['email_address']==i]\n",
    "    #     print(email_specific.shape,'\\n')\n",
    "\n",
    "        if email_specific.shape[0] == 1:\n",
    "            data = email_specific.to_dict('record')[0]\n",
    "    #         print(data)\n",
    "\n",
    "        else:\n",
    "\n",
    "            for num in range(0,10):\n",
    "                column_specific = sub_df(num)\n",
    "    #             display(column_specific)\n",
    "\n",
    "                # Extract first names to filter out based on frequency for golden record\n",
    "                col = column_specific.iloc[:,1].tolist()\n",
    "    #             print('col: ',col,'\\n')\n",
    "\n",
    "                # Get frequency counts of each of the names\n",
    "                col_count = {x:col.count(x) for x in col}\n",
    "    #             print(\"col_count:\",col_count,'\\n')\n",
    "\n",
    "\n",
    "                # length of dictionary is greater than length of distinct counts in dictionary, indicates of multiple \n",
    "                # distinct values for that attribute >> can easily calculate most frequent value\n",
    "                # max  value counts == 1 selects only records that do not have ties in duplicate records\n",
    "                if column_specific.shape[0] == 0:\n",
    "                    for i in column_specific.columns[1:]:\n",
    "                        data[i]= np.nan\n",
    "\n",
    "                elif (len(col_count) > len(set(col_count.values()))) \\\n",
    "                    & (sum(x==max(col_count.values()) for x in col_count.values()) == 1):\n",
    "\n",
    "                    # Getting most frequent value of column\n",
    "                    freq_value = max(col_count, key=col_count.get)\n",
    "    #                 print('freq_value:',freq_value,'\\n')\n",
    "\n",
    "                    # Extracting rows that contain the most frequent value\n",
    "                    freq_df = column_specific[column_specific.iloc[:,1] == freq_value]\n",
    "    #                 print('freq_df')\n",
    "    #                 display(freq_df)\n",
    "\n",
    "                    val = freq_df.to_dict('records')\n",
    "                    data.update(val[0])\n",
    "\n",
    "                else:\n",
    "                    # Count number of columns that have max non-null values \n",
    "                    count = max(column_specific.count(axis=1))\n",
    "        #             print(\"count:\",count,'\\n')\n",
    "\n",
    "                    # Get rows with maximum number of non-null values\n",
    "                    min_df = column_specific.dropna(thresh=max(column_specific.count(axis=1)))\n",
    "                    min_df['date_created'] = pd.to_datetime(min_df['date_created'])#,errors = 'coerce')\n",
    "    #                 print('min_df')\n",
    "    #                 print(min_df,'\\n')\n",
    "\n",
    "                    # No date created, take the last value in list\n",
    "                    if (min_df['date_created'].isnull().values.any() == True):\n",
    "\n",
    "                        last_value = (min_df.iloc[:,1:].iloc[-1] if len(min_df.iloc[:,1:]) > 1 else min_df.iloc[:,1:])\n",
    "    #                     print('last_value:','\\n',last_value,'\\n')\n",
    "                        val = last_value.to_dict('records')\n",
    "                        data.update(val[0])\n",
    "\n",
    "                    else:\n",
    "                        date_created = max(min_df['date_created'].tolist())\n",
    "    #                     print('date_created:',date_created)\n",
    "\n",
    "                        recent_record = min_df[min_df['date_created']==date_created].iloc[:,1:]#.values.tolist()[0]\n",
    "                        val = recent_record.to_dict('records')\n",
    "    #                     display(recent_record,'\\n')\n",
    "                        data.update(val[0])\n",
    "\n",
    "        # Final dataframe to import into postgres\n",
    "    #     print('data:','\\n')\n",
    "        data_df = pd.DataFrame(data.items())\n",
    "        data_df = data_df.set_index(0).T\n",
    "        data_df = data_df.where(pd.notnull(data_df), None)\n",
    "    #     display(data_df)\n",
    "\n",
    "        data_df.to_sql(name='master_customer_test', con=postgres_engine, if_exists='append', index=False, method='multi')\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e.message,e.args)\n",
    "#         failed_emails[i]=e\n",
    "#         count_failed_emails += 1\n",
    "#         pass\n",
    "    \n",
    "    print('-------------------')\n",
    "#     print('-------------------')\n",
    "\n",
    "# failed_emails = pd.DataFrame(failed_emails.items(), columns=['Emails', 'ErrorType'])\n",
    "# failed_emails.groupby(['ErrorType']).sum()\n",
    "# print(\"failed_emails: \",'\\n',failed_emails)\n",
    "# print(\"count_failed_emails: \",count_failed_emails)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tow = ['a','b','c',4,'e',8]\n",
    "x = {}\n",
    "\n",
    "try:\n",
    "    for i in tow:\n",
    "        if i % 2 == 0:\n",
    "            print(\"Yes\")\n",
    "except TypeError as e:\n",
    "    x[i]=e\n",
    "    \n",
    "print(x)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tow = ['a','b','c',4,'e',8]\n",
    "\n",
    "for i in tow:\n",
    "    try:\n",
    "        if i % 2 == 0:\n",
    "            print(\"Yes\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
