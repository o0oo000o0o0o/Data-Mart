{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine, inspect\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "from config import host, user, user1, password, password1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "postgres_engine = create_engine(f'postgresql://{user1}:{password1}@{host}:5432/staging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PostgreSQL Connection Established\n"
     ]
    }
   ],
   "source": [
    "#PostgreSQL Connection\n",
    "try:\n",
    "    pg_db = psycopg2.connect(host=host,user=user1,password=password1,database=\"staging\")\n",
    "    pg_db.autocommit = True\n",
    "    pgcursor = pg_db.cursor()\n",
    "    print(\"PostgreSQL Connection Established\")\n",
    "except psycopg2.OperationalError as e:\n",
    "    print(\"Unable to Connect: \",format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stg_crm = pd.read_sql('SELECT * FROM stg_crm_customer', con=postgres_engine)\n",
    "stg_bpm = pd.read_sql('SELECT * FROM stg_bpm_client_info', con=postgres_engine)\n",
    "stg_blc = pd.read_sql('SELECT * FROM stg_blc_customer', con=postgres_engine)\n",
    "master = pd.read_sql('SELECT * FROM master_customer_test', con=postgres_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crm[\"source_table\"] = \"CRM_Customer\"\n",
    "stg_crm[\"role_id\"] = 1\n",
    "stg_crm = stg_crm.rename(columns={\"locality\": \"city\", \"region\": \"state\", \"country_code\": \"country\", \n",
    "                          \"given_name\": \"first_name\", \"phonenumber\": \"phone\", \"address1\": \"address_line1\", \n",
    "                          \"address2\": \"address_line2\", \"zip_code\": \"zip\"})\n",
    "stg_crm = stg_crm[['customer_id', 'email_address', 'date_created', 'first_name','country', 'phone', 'email_status', \n",
    "           'created_date', 'updated_date','role_id']]#,'source_table']]\n",
    "stg_crm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Validating Email_addresses Using REGEX\n",
    "crm = stg_crm[stg_crm.email_address.str.contains('[\\w\\.-]+@[\\w\\.-]+', regex= True, na=False)]\n",
    "crm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stg_crm[~stg_crm.isin(crm)].dropna()\n",
    "# .shape = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_master = master.append(crm)\n",
    "# new_master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stg_bpm.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bpm[\"source_table\"] = \"BPM_Client_INFO\"\n",
    "stg_bpm[\"role_id\"] = 1\n",
    "stg_bpm = stg_bpm.rename(columns={\"company_name\": \"publisher_name\", \"email\": \"email_address\", \"address\": \"address_line1\", \"date\": \"date_of_sale\", \"clientid\": \"customer_id\"})\n",
    "stg_bpm = stg_bpm[['customer_id', 'publisher_name', 'address_line1', 'city', 'state','country', 'zip', 'phone', 'fax', \n",
    "           'email_address','date_of_sale', 'created_date', 'updated_date','role_id']]#,'source_table']]\n",
    "stg_bpm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Validating Email_addresses Using REGEX\n",
    "bpm = stg_bpm[stg_bpm.email_address.str.contains('[\\w\\.-]+@[\\w\\.-]+', regex= True, na=False)]\n",
    "bpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = pd.merge(stg_bpm,bpm,on='customer_id',how='outer',indicator=True)\n",
    "# result=result[result['_merge']=='left_only']\n",
    "# print(result.shape)\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pandas import ExcelWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writer = ExcelWriter('MissingEmailBPM.xlsx')\n",
    "# result.to_excel(writer,'Sheet1')\n",
    "# writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one[one.isin(result)]\n",
    "# from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in result['publisher_name_x'].unique():\n",
    "#     column_specific = stg_bpm[(stg_bpm['publisher_name']==i)]\n",
    "# #     if column_specific.shape[0] > 1:\n",
    "# #         display(column_specific)\n",
    "        \n",
    "# #         # Howard Shapiro\n",
    "# #         # Colleen Sen\n",
    "        \n",
    "# #     else:\n",
    "#     display(column_specific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_master = new_master.append(bpm)\n",
    "new_master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stg_blc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stg_blc[\"source_table\"] = \"BLC_Customer_Updated\"\n",
    "stg_blc = stg_blc[['customer_id', 'date_created','deactivated', 'email_address','first_name', 'last_name', 'password', \n",
    "           'user_name', 'address_line1', 'city', 'phone', 'zip','country_name', 'state_name', 'role_id',\n",
    "           'is_publisher', 'publisher_name', 'website', 'is_partner', 'date_of_sale','lead_owner', \n",
    "           'lead_source', 'order_type', 'created_date','updated_date']]\n",
    "stg_blc = stg_blc.rename(columns={\"country_name\": \"country\", \"state_name\": \"state\"})\n",
    "stg_blc = stg_blc.loc[(stg_blc[\"role_id\"] == 1) & pd.notnull(stg_blc[\"address_line1\"])]\n",
    "stg_blc = stg_blc.fillna('1')\n",
    "\n",
    "stg_blc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validating Email_addresses Using REGEX\n",
    "blc = stg_blc[stg_blc.email_address.str.contains('[\\w\\.-]+@[\\w\\.-]+', regex= True, na=False)]\n",
    "blc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blc[blc.isin(x)].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_master = new_master.append(blc)\n",
    "# new_master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MASTER CUSTOMER TABLE AND GOLDEN RECORD CREATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_master['email_address'] = new_master['email_address'].str.lower()\n",
    "new_master = new_master.replace({\"\\'\":\"''\" }, regex=True)\n",
    "new_master = new_master.replace(r'^([\\s])$|^(?![\\s\\S])$', np.nan, regex=True)\n",
    "new_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_master['email_address'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in new_master['email_address'].unique():\n",
    "    print(i)\n",
    "    \n",
    "# ### FIRST_NAME\n",
    "#     # Creating a new dataframe using rows that have email_address = i\n",
    "#     column_specific = new_master[(new_master['email_address']==i) & (new_master['first_name'].isna()==False)]\n",
    "# #     print(column_specific)\n",
    "    \n",
    "#     if column_specific.shape[0] == 0:\n",
    "#         first_name = np.nan\n",
    "#         print(\"FIRST_NAME:\",first_name,'\\n')\n",
    "        \n",
    "#     elif column_specific.shape[0] == 1:\n",
    "        \n",
    "#         first_name = column_specific.iloc[0].last_name\n",
    "#         print(\"FIRST_NAME:\",first_name,'\\n')\n",
    "        \n",
    "#     else:\n",
    "#         # Extract first names to filter out based on frequency for golden record\n",
    "#         fn = column_specific['first_name'].tolist()\n",
    "\n",
    "#         # Get frequency counts of each of the names\n",
    "#         first_names = {x:fn.count(x) for x in fn}\n",
    "#     #     print(\"first_name:\",first_names)\n",
    "\n",
    "#         # Checking for ties in frequencies by finding unique counts values\n",
    "#         first_name_set = set(val for val in first_names.values())\n",
    "#     #     print(\"First Name Counts:\",first_name_set)\n",
    "\n",
    "#         # if lengths of dictionary and set are equal = no ties between names = get value with highest frequency\n",
    "#         # if lengths are not equal = frequencies tied between two names = get the oldest name\n",
    "#         if len(first_name_set) == len(first_names):\n",
    "#             first_name = max(first_names, key=first_names.get)\n",
    "#             print(\"FIRST_NAME:\",first_name,'\\n')\n",
    "\n",
    "#     #         print(\"---------\")\n",
    "#         else:\n",
    "#             date_created = min(column_specific['date_created'].tolist())\n",
    "#     #         print(date_created)\n",
    "\n",
    "#             idx = column_specific[column_specific['date_created']==date_created].index\n",
    "#             first_name = list(column_specific.loc[idx,'first_name'])[0]\n",
    "#             print(\"FIRST_NAME:\",first_name,'\\n')\n",
    "\n",
    "#     #         print(\"---------\")\n",
    "        \n",
    "# ### LAST_NAME    \n",
    "#     # extracting those rows that have email_addresses = i\n",
    "#     column_specific = new_master[(new_master['email_address']==i) & (new_master['last_name'].isna()==False)]\n",
    "# #     print(column_specific)\n",
    "    \n",
    "#     if column_specific.shape[0] == 0:\n",
    "#         last_name = np.nan\n",
    "#         print('last_name:',last_name,'\\n')\n",
    "        \n",
    "#     elif column_specific.shape[0] == 1:\n",
    "        \n",
    "#         last_name = column_specific.iloc[0].last_name\n",
    "#         print('last_name:',last_name,'\\n')\n",
    "        \n",
    "#     else:\n",
    "\n",
    "#         # extract values to filter out based on frequency for golden record\n",
    "#         ln = column_specific['last_name'].tolist()\n",
    "#     #     print(ln)\n",
    "\n",
    "#         #Get frequency counts of each last name in list\n",
    "#         last_names = {x:ln.count(x) for x in ln}\n",
    "#     #     print(\"last name:\",last_names)\n",
    "\n",
    "#         # Checking for ties in frequencies by finding unique counts values\n",
    "#         last_name_set = set(val for val in last_names.values())\n",
    "#     #     print(\"last_name_set:\",last_name_set)\n",
    "\n",
    "#         # if lengths of dictionary and set are equal = no ties between names = get value with highest frequency\n",
    "#         # if lengths are not equal = frequencies tied between two names = get the oldest name\n",
    "#         if len(last_name_set) == len(last_names):\n",
    "#             last_name = max(last_names, key=last_names.get)\n",
    "#             print('last_name:',last_name,'\\n')\n",
    "\n",
    "#     #         print(\"---------\")\n",
    "#         else:\n",
    "#             date_created = min(column_specific['date_created'].tolist())\n",
    "#     #         print(date_created)\n",
    "\n",
    "#             idx = column_specific[column_specific['date_created']==date_created].index\n",
    "#     #         print(idx)\n",
    "#             last_name = list(column_specific.loc[idx,'last_name'])[0]\n",
    "#             print('last_name:',last_name,'\\n')\n",
    "\n",
    "#     #         print(\"---------\")\n",
    "\n",
    "\n",
    "### ADDRESS\n",
    "\n",
    "    # extracting address columns and rows that satisfy two conditions: \n",
    "    # email_addresses = i and address_line1 is not NaN\n",
    "    column_specific = new_master[['date_created','address_line1','address_line2','city','state','country','zip']][(new_master['email_address']==i) & (new_master['address_line1'].isna()==False)]\n",
    "#     print(column_specific,'\\n')\n",
    "    \n",
    "    if column_specific.shape[0] == 0:\n",
    "        adl1 = adl2 = city = state = country = zip = np.nan\n",
    "#         print('Address_line1:',adl1)\n",
    "#         print('Address_line2:',adl2)\n",
    "#         print('city:',city)\n",
    "#         print('state:',state)\n",
    "#         print('Country:',country)\n",
    "#         print('zip:',zip,'\\n')\n",
    "        \n",
    "    elif column_specific.shape[0] == 1:\n",
    "        adl1 = column_specific.iloc[0].address_line1\n",
    "        adl2 = column_specific.iloc[0].address_line2\n",
    "        city = column_specific.iloc[0].city\n",
    "        state = column_specific.iloc[0].state\n",
    "        country = column_specific.iloc[0].country\n",
    "        zip = column_specific.iloc[0].zip\n",
    "#         print('Address_line1:',adl1)\n",
    "#         print('Address_line2:',adl2)\n",
    "#         print('city:',city)\n",
    "#         print('state:',state)\n",
    "#         print('Country:',country)\n",
    "#         print('zip:',zip,'\\n')\n",
    "#         print('------------')\n",
    "        \n",
    "    else:\n",
    "        # extract addresses to filter out based on frequency for golden record\n",
    "        address_lst = column_specific['address_line1'].tolist()\n",
    "#         print(\"address_lst:\",address_lst,'\\n')\n",
    "\n",
    "        #Frequency counts of each address in list\n",
    "        address_counts = {x:address_lst.count(x) for x in address_lst}\n",
    "        \n",
    "#         print(\"address_counts:\",address_counts,\":: set counts:\",set(address_counts.values()),'\\n')\n",
    "\n",
    "        # A set cannot have duplicate values, it takes the unique of dictionary values. \n",
    "        # Length of set = 1 only when all values in dictionary are the same [Ties might exist]\n",
    "        if (len(address_counts) > len(set(address_counts.values()))) \\\n",
    "                & (sum(x==max(address_counts.values()) for x in address_counts.values()) == 1):\n",
    "            \n",
    "            # Getting most frequent value of column\n",
    "            freq_value = max(address_counts, key=address_counts.get)\n",
    "#             print('freq_value:',freq_value,'\\n')\n",
    "            \n",
    "            # Extracting rows that contain the most frequent value\n",
    "            freq_df = column_specific[column_specific['address_line1'] == freq_value]\n",
    "            \n",
    "            adl1 = freq_df.iloc[0].address_line1\n",
    "            adl2 = freq_df.iloc[0].address_line2\n",
    "            city = freq_df.iloc[0].city\n",
    "            state = freq_df.iloc[0].state\n",
    "            country = freq_df.iloc[0].country\n",
    "            zip = freq_df.iloc[0].zip\n",
    "#             print('Address_line1:',adl1)\n",
    "#             print('Address_line2:',adl2)\n",
    "#             print('city:',city)\n",
    "#             print('state:',state)\n",
    "#             print('Country:',country)\n",
    "#             print('zip:',zip,'\\n')\n",
    "        \n",
    "#             print('FINAL FREQ RECORD')\n",
    "#             print(freq_df,'\\n')\n",
    "\n",
    "#             print('-----------')\n",
    "#             print('-----------')\n",
    "        else:\n",
    "            \n",
    "            # Selecting rows with minimum missing values\n",
    "            # Count number of columns that have max non-null values \n",
    "#             count = max(column_specific.count(axis=1))\n",
    "#             print(\"count:\",count,'\\n')\n",
    "            \n",
    "            # Get rows with maximum number of non-null values\n",
    "            min_df = column_specific.dropna(thresh=max(column_specific.count(axis=1)))\n",
    "            min_df['date_created'] = pd.to_datetime(min_df['date_created'],errors = 'coerce')\n",
    "#             print('min_df')\n",
    "#             print(min_df,'\\n')\n",
    "\n",
    "            if (min_df.shape[0]==1) or (min_df['date_created'].isnull().values.any() == True):\n",
    "                adl1 = min_df.iloc[0].address_line1\n",
    "                adl2 = min_df.iloc[0].address_line2\n",
    "                city = min_df.iloc[0].city\n",
    "                state = min_df.iloc[0].state\n",
    "                country = min_df.iloc[0].country\n",
    "                zip = min_df.iloc[0].zip\n",
    "                print('Address_line1:',adl1)\n",
    "                print('Address_line2:',adl2)\n",
    "                print('city:',city)\n",
    "                print('state:',state)\n",
    "                print('Country:',country)\n",
    "                print('zip:',zip,'\\n')\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                # Extract the most recent record of the above dataframe\n",
    "#                 print(min_df)\n",
    "                \n",
    "                date_created = max(min_df['date_created'].tolist())\n",
    "#                 print('date_created:',type(date_created))\n",
    "#                 print('date_created:',date_created)\n",
    "            \n",
    "                recent_record = min_df[min_df['date_created']==date_created]#.iloc[:,1:]#.values.tolist()[0]\n",
    "#                 print('recent_record:',recent_record)\n",
    "\n",
    "                adl1 = recent_record.iloc[0].address_line1\n",
    "                adl2 = recent_record.iloc[0].address_line1\n",
    "                city = recent_record.iloc[0].city\n",
    "                state = recent_record.iloc[0].state\n",
    "                country = recent_record.iloc[0].country\n",
    "                zip = recent_record.iloc[0].zip\n",
    "#                 print('Address_line1:',adl1)\n",
    "#                 print('Address_line2:',adl2)\n",
    "#                 print('city:',city)\n",
    "#                 print('state:',state)\n",
    "#                 print('Country:',country)\n",
    "#                 print('zip:',zip,'\\n')\n",
    "            \n",
    "#             print('-----------')\n",
    "#             print('-----------')\n",
    "\n",
    "# ### PHONE\n",
    "\n",
    "#     # extracting address columns and rows that satisfy two conditions: \n",
    "#     # email_addresses = i and address_line1 is not NaN\n",
    "#     column_specific = new_master[['date_created','phone']][(new_master['email_address']==i) & (new_master['phone'].isna()==False)]\n",
    "#     column_specific['phone'] = column_specific['phone'].str.replace('\\W', '')\n",
    "# #     print(column_specific,'\\n')\n",
    "    \n",
    "#     if column_specific.shape[0] == 0:\n",
    "#         phone_number = np.nan\n",
    "#         print('PHONE_NUMBER:',phone_number,'\\n')\n",
    "        \n",
    "#     elif column_specific.shape[0] == 1:\n",
    "        \n",
    "#         phone_number = column_specific.iloc[0].phone\n",
    "#         print('PHONE_NUMBER:',phone_number,'\\n')\n",
    "        \n",
    "#     else:\n",
    "#         # extract addresses to filter out based on frequency for golden record\n",
    "#         phn_lst = column_specific['phone'].tolist()\n",
    "# #         print(\"phn_lst:\",phn_lst,'\\n')\n",
    "\n",
    "#         #Frequency counts of each address in list\n",
    "#         phone_counts = {x:phn_lst.count(x) for x in phn_lst}\n",
    "# #         print(\"phone_counts:\",phone_counts,\":: set counts:\",set(phone_counts.values()),'\\n')\n",
    "        \n",
    "#         if len(phone_counts) == 1:\n",
    "#             phone_number = list(phone_counts.keys())[0]\n",
    "#             print('PHONE_NUMBER:',phone_number,'\\n')\n",
    "        \n",
    "#         else:\n",
    "        \n",
    "#             # Extract the most recent record of the above dataframe\n",
    "#             column_specific['date_created'] = pd.to_datetime(column_specific['date_created'],errors = 'coerce')\n",
    "# #             print(type(column_specific['date_created']))\n",
    "\n",
    "#             if column_specific['date_created'].isnull().values.any() == True:\n",
    "#                 phone_number = column_specific['phone'].values.tolist()\n",
    "#                 phone_number = (phone_number[-1] if len(phone_number) > 1 else phone_number)\n",
    "#                 print('PHONE_NUMBER:',phone_number,'\\n')\n",
    "                \n",
    "#             else:\n",
    "                \n",
    "#                 # Extract the most recent record of the above dataframe\n",
    "#                 date_created = max(column_specific['date_created'].tolist())\n",
    "\n",
    "#                 phone_number = column_specific['phone'][(column_specific['date_created']==date_created)].values.tolist()\n",
    "#                 print('PHONE_NUMBER:',phone_number,'\\n')\n",
    "                \n",
    "\n",
    "# #     print(\"--------\")\n",
    "    \n",
    "#     insrt_cmd = \"INSERT INTO mct(customer_id,first_name,last_name,address_line1,address_line2,city,state,country,zip,phone) VALUES (1,'\"+str(first_name)+\"','\"+str(last_name)+\"','\"+str(adl1)+\"','\"+str(adl2)+\"','\"+str(city)+\"','\"+str(state)+\"','\"+str(country)+\"','\"+str(zip)+\"','\"+str(phone_number)+\"')\" \n",
    "#     print(insrt_cmd)\n",
    "# #     pgcursor.execute(insrt_cmd)\n",
    "    \n",
    "    print(\"---------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insrt_cmd1 = \"INSERT INTO stg_BLC_CUSTOMER(first_name,last_name,address_line1,address_line2,city,state,country,zip,phone) \" \\\n",
    "#             \"VALUES ('\"+first_name+\"','\"+last_name+\"','\"+address_line1+\"','\"+address_line2+\"','\"+city+\"','\"+state+\"','\"+country+\"','\"+zip+\"','\"+phone\"')\" \n",
    "# pgcursor.execute(insrt_cmd1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pgcursor.execute(insrt_cmd1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_master[\"master_customer_id\"] = range(1, 1+len(new_master))\n",
    "# new_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_master.to_sql(name='master_customer_test', con=postgres_engine, if_exists='append', index=False, method='multi')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
